{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8586417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a9d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = load_model('smnist.h5')\n",
    "letterpred = [chr(i) for i in range(65, 91) if chr(i) != 'J' and chr(i) != 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6de75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d716a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Character 1: Y (Confidence: 57.34%)\n",
      "Predicted Character 2: W (Confidence: 25.18%)\n",
      "Predicted Character 3: P (Confidence: 16.34%)\n",
      "Predicted Character 1: P (Confidence: 94.41%)\n",
      "Predicted Character 2: H (Confidence: 2.08%)\n",
      "Predicted Character 3: T (Confidence: 0.89%)\n",
      "Predicted Character 1: P (Confidence: 45.49%)\n",
      "Predicted Character 2: K (Confidence: 34.27%)\n",
      "Predicted Character 3: N (Confidence: 20.04%)\n",
      "Predicted Character 1: P (Confidence: 99.97%)\n",
      "Predicted Character 2: O (Confidence: 0.02%)\n",
      "Predicted Character 3: N (Confidence: 0.01%)\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "_, frame = cap.read()\n",
    "h, w, _ = frame.shape\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    if k % 256 == 27:  # ESC to exit\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k % 256 == 32:  # SPACE to predict\n",
    "        analysisframe = frame.copy()\n",
    "        framergbanalysis = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2RGB)\n",
    "        resultanalysis = hands.process(framergbanalysis)\n",
    "        hand_landmarksanalysis = resultanalysis.multi_hand_landmarks\n",
    "        if hand_landmarksanalysis:\n",
    "            for handLMsanalysis in hand_landmarksanalysis:\n",
    "                x_max, y_max, x_min, y_min = 0, 0, w, h\n",
    "                for lmanalysis in handLMsanalysis.landmark:\n",
    "                    x, y = int(lmanalysis.x * w), int(lmanalysis.y * h)\n",
    "                    x_max, x_min = max(x_max, x), min(x_min, x)\n",
    "                    y_max, y_min = max(y_max, y), min(y_min, y)\n",
    "                y_min, y_max = max(0, y_min-20), min(h, y_max+20)\n",
    "                x_min, x_max = max(0, x_min-20), min(w, x_max+20)\n",
    "                analysisframe = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2GRAY)\n",
    "                analysisframe = analysisframe[y_min:y_max, x_min:x_max]\n",
    "                analysisframe = cv2.resize(analysisframe, (28,28))\n",
    "                pixeldata = analysisframe.reshape(1,28,28,1) / 255.0\n",
    "                prediction = model.predict(pixeldata)\n",
    "                predarray = prediction[0]\n",
    "                top3 = predarray.argsort()[-3:][::-1]\n",
    "                for i, idx in enumerate(top3):\n",
    "                    print(f\"Predicted Character {i+1}: {letterpred[idx]} (Confidence: {predarray[idx]*100:.2f}%)\")\n",
    "                time.sleep(2)\n",
    "    # Draw hand landmarks\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "    if hand_landmarks:\n",
    "        for handLMs in hand_landmarks:\n",
    "            x_max, y_max, x_min, y_min = 0, 0, w, h\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                x_max, x_min = max(x_max, x), min(x_min, x)\n",
    "                y_max, y_min = max(y_max, y), min(y_min, y)\n",
    "            y_min, y_max = max(0, y_min-20), min(h, y_max+20)\n",
    "            x_min, x_max = max(0, x_min-20), min(w, x_max+20)\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0,255,0), 2)\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a07f35",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
